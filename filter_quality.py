#!/usr/bin/env python
"""
Quality Filtering CLI

MVP Phase 2 Week 6: Quality Filtering
- Confidence score í•„í„°ë§
- Jittering ì ìˆ˜ ê³„ì‚°
- ìƒìœ„ 50% ë°ì´í„°ë§Œ ì €ì¥

ì‚¬ìš©ë²•:
    python filter_quality.py --all                     # ëª¨ë“  í¬ì¦ˆ íŒŒì¼ í•„í„°ë§
    python filter_quality.py --file data/poses/x.npz  # ë‹¨ì¼ íŒŒì¼ ë¶„ì„
    python filter_quality.py --analyze                 # í’ˆì§ˆ ë¶„ì„ ë¦¬í¬íŠ¸
    python filter_quality.py --top-percent 50          # ìƒìœ„ 50% ì„ íƒ
"""

import os
import sys
import argparse
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import shutil

import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from core.logging_config import setup_logger
from core.quality_metrics import (
    QualityMetricCalculator,
    QualityThresholds,
    PoseQualityMetrics,
)

logger = setup_logger(__name__)


@dataclass
class FilterResult:
    """í•„í„°ë§ ê²°ê³¼"""
    file_path: str
    video_id: str
    passed: bool
    quality_score: float
    confidence_mean: float
    jitter_score: float
    nan_ratio: float
    total_frames: int
    failure_reasons: List[str]


class QualityFilter:
    """í’ˆì§ˆ í•„í„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        thresholds: Optional[QualityThresholds] = None,
        poses_dir: str = "data/poses",
        filtered_dir: str = "data/filtered",
    ):
        self.thresholds = thresholds or QualityThresholds()
        self.calculator = QualityMetricCalculator(self.thresholds)
        self.poses_dir = Path(poses_dir)
        self.filtered_dir = Path(filtered_dir)
    
    def analyze_file(self, file_path: Path) -> FilterResult:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        try:
            data = np.load(file_path, allow_pickle=True)
            
            # í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ (ì—¬ëŸ¬ í‚¤ ì§€ì›)
            poses = None
            for key in ["poses", "body", "keypoints"]:
                if key in data:
                    poses = data[key]
                    break
            
            if poses is None:
                raise ValueError(f"í¬ì¦ˆ ë°ì´í„° ì—†ìŒ (keys: {list(data.keys())})")
            
            # [T, J*4] -> [T, J, 4] ë³€í™˜ (í•„ìš”ì‹œ)
            if len(poses.shape) == 2:
                num_joints = poses.shape[1] // 4
                poses = poses.reshape(-1, num_joints, 4)
            
            # [T, J, 3] -> [T, J, 4] ë³€í™˜ (visibility ì¶”ê°€)
            if len(poses.shape) == 3 and poses.shape[2] == 3:
                # visibilityê°€ ë³„ë„ ë°°ì—´ë¡œ ìˆëŠ”ì§€ í™•ì¸
                visibility = np.ones((poses.shape[0], poses.shape[1]), dtype=np.float32)
                poses_with_vis = np.concatenate([
                    poses,
                    visibility[:, :, np.newaxis]
                ], axis=2)
                poses = poses_with_vis
            
            # ì‹ ë¢°ë„ ë°ì´í„° (ì—¬ëŸ¬ í‚¤ ì§€ì›)
            confidences = None
            for key in ["confidences", "confidence", "conf"]:
                if key in data:
                    confidences = data[key]
                    break
            
            # í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°
            metrics = self.calculator.calculate_pose_quality(poses, confidences)
            
            # ë¹„ë””ì˜¤ ID ì¶”ì¶œ
            video_id = file_path.stem.replace("_pose", "")
            
            return FilterResult(
                file_path=str(file_path),
                video_id=video_id,
                passed=metrics.passed,
                quality_score=metrics.quality_score,
                confidence_mean=metrics.confidence_mean,
                jitter_score=metrics.jitter_score,
                nan_ratio=metrics.nan_ratio,
                total_frames=metrics.total_frames,
                failure_reasons=metrics.failure_reasons,
            )
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {file_path}: {e}")
            return FilterResult(
                file_path=str(file_path),
                video_id=file_path.stem.replace("_pose", ""),
                passed=False,
                quality_score=0.0,
                confidence_mean=0.0,
                jitter_score=0.0,
                nan_ratio=1.0,
                total_frames=0,
                failure_reasons=[f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"],
            )
    
    def analyze_all(self) -> List[FilterResult]:
        """ëª¨ë“  í¬ì¦ˆ íŒŒì¼ ë¶„ì„"""
        results = []
        
        pose_files = list(self.poses_dir.glob("*_pose.npz"))
        
        if not pose_files:
            logger.warning(f"í¬ì¦ˆ íŒŒì¼ ì—†ìŒ: {self.poses_dir}")
            return results
        
        print(f"\n{'='*60}")
        print(f"ğŸ” í’ˆì§ˆ ë¶„ì„ ì‹œì‘")
        print(f"{'='*60}")
        print(f"ğŸ“ ê²½ë¡œ: {self.poses_dir}")
        print(f"ğŸ“¦ íŒŒì¼: {len(pose_files)}ê°œ")
        print()
        
        for i, file_path in enumerate(pose_files, 1):
            result = self.analyze_file(file_path)
            results.append(result)
            
            status = "âœ… PASS" if result.passed else "âŒ FAIL"
            print(f"[{i}/{len(pose_files)}] {result.video_id}: {status} "
                  f"(score={result.quality_score:.2f}, conf={result.confidence_mean:.2f})")
        
        return results
    
    def filter_by_threshold(
        self,
        results: Optional[List[FilterResult]] = None,
        copy_files: bool = True,
    ) -> Tuple[List[FilterResult], List[FilterResult]]:
        """ì„ê³„ê°’ ê¸°ë°˜ í•„í„°ë§"""
        if results is None:
            results = self.analyze_all()
        
        passed = [r for r in results if r.passed]
        failed = [r for r in results if not r.passed]
        
        if copy_files and passed:
            self.filtered_dir.mkdir(parents=True, exist_ok=True)
            
            for result in passed:
                src = Path(result.file_path)
                dst = self.filtered_dir / src.name
                shutil.copy2(src, dst)
        
        return passed, failed
    
    def filter_top_percent(
        self,
        results: Optional[List[FilterResult]] = None,
        top_percent: float = 50.0,
        copy_files: bool = True,
    ) -> List[FilterResult]:
        """ìƒìœ„ N% ì„ íƒ"""
        if results is None:
            results = self.analyze_all()
        
        # í’ˆì§ˆ ì ìˆ˜ë¡œ ì •ë ¬
        sorted_results = sorted(results, key=lambda r: r.quality_score, reverse=True)
        
        # ìƒìœ„ N% ì„ íƒ
        top_count = max(1, int(len(sorted_results) * (top_percent / 100)))
        top_results = sorted_results[:top_count]
        
        if copy_files and top_results:
            self.filtered_dir.mkdir(parents=True, exist_ok=True)
            
            for result in top_results:
                src = Path(result.file_path)
                dst = self.filtered_dir / src.name
                shutil.copy2(src, dst)
        
        return top_results
    
    def generate_report(
        self,
        results: List[FilterResult],
        output_path: Optional[str] = None,
    ) -> Dict[str, Any]:
        """í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not results:
            return {"error": "ë¶„ì„ ê²°ê³¼ ì—†ìŒ"}
        
        passed = [r for r in results if r.passed]
        failed = [r for r in results if not r.passed]
        
        # í†µê³„ ê³„ì‚°
        quality_scores = [r.quality_score for r in results]
        confidence_means = [r.confidence_mean for r in results]
        jitter_scores = [r.jitter_score for r in results]
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "thresholds": asdict(self.thresholds),
            "summary": {
                "total_files": len(results),
                "passed": len(passed),
                "failed": len(failed),
                "pass_rate": len(passed) / len(results) * 100 if results else 0,
            },
            "quality_stats": {
                "score_mean": float(np.mean(quality_scores)),
                "score_std": float(np.std(quality_scores)),
                "score_min": float(np.min(quality_scores)),
                "score_max": float(np.max(quality_scores)),
                "score_median": float(np.median(quality_scores)),
            },
            "confidence_stats": {
                "mean": float(np.mean(confidence_means)),
                "std": float(np.std(confidence_means)),
                "min": float(np.min(confidence_means)),
                "max": float(np.max(confidence_means)),
            },
            "jitter_stats": {
                "mean": float(np.mean(jitter_scores)),
                "std": float(np.std(jitter_scores)),
                "min": float(np.min(jitter_scores)),
                "max": float(np.max(jitter_scores)),
            },
            "failure_analysis": self._analyze_failures(failed),
            "passed_files": [asdict(r) for r in passed],
            "failed_files": [asdict(r) for r in failed],
        }
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            logger.info(f"ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")
        
        return report
    
    def _analyze_failures(self, failed: List[FilterResult]) -> Dict[str, int]:
        """ì‹¤íŒ¨ ì›ì¸ ë¶„ì„"""
        reasons = {}
        for result in failed:
            for reason in result.failure_reasons:
                # ì›ì¸ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                category = reason.split("=")[0] if "=" in reason else reason
                reasons[category] = reasons.get(category, 0) + 1
        return reasons
    
    def print_summary(self, results: List[FilterResult]):
        """ìš”ì•½ ì¶œë ¥"""
        if not results:
            print("ë¶„ì„ ê²°ê³¼ ì—†ìŒ")
            return
        
        passed = [r for r in results if r.passed]
        failed = [r for r in results if not r.passed]
        
        print()
        print("="*60)
        print("ğŸ“Š í’ˆì§ˆ í•„í„°ë§ ê²°ê³¼")
        print("="*60)
        
        print(f"\nğŸ“ˆ ìš”ì•½:")
        print(f"   ì´ íŒŒì¼: {len(results)}ê°œ")
        print(f"   âœ… í†µê³¼: {len(passed)}ê°œ ({len(passed)/len(results)*100:.1f}%)")
        print(f"   âŒ ì‹¤íŒ¨: {len(failed)}ê°œ ({len(failed)/len(results)*100:.1f}%)")
        
        if results:
            scores = [r.quality_score for r in results]
            print(f"\nğŸ“Š í’ˆì§ˆ ì ìˆ˜:")
            print(f"   í‰ê· : {np.mean(scores):.3f}")
            print(f"   í‘œì¤€í¸ì°¨: {np.std(scores):.3f}")
            print(f"   ìµœì†Œ: {np.min(scores):.3f}")
            print(f"   ìµœëŒ€: {np.max(scores):.3f}")
        
        if failed:
            print(f"\nâŒ ì‹¤íŒ¨ ì›ì¸:")
            failure_analysis = self._analyze_failures(failed)
            for reason, count in sorted(failure_analysis.items(), key=lambda x: -x[1]):
                print(f"   - {reason}: {count}ê°œ")
        
        print()


def update_database_quality(
    results: List[FilterResult],
    db_path: str = "data/pade.db"
):
    """DBì— í’ˆì§ˆ ì ìˆ˜ ì—…ë°ì´íŠ¸"""
    try:
        from sqlalchemy import create_engine
        from sqlalchemy.orm import sessionmaker
        from models.database import Episode
        
        engine = create_engine(f"sqlite:///{db_path}")
        Session = sessionmaker(bind=engine)
        session = Session()
        
        updated = 0
        for result in results:
            # video_idë¡œ ì—í”¼ì†Œë“œ ì°¾ê¸°
            episodes = session.query(Episode).filter(
                Episode.episode_id.like(f"{result.video_id}%")
            ).all()
            
            for ep in episodes:
                ep.quality_score = result.quality_score
                ep.confidence_score = result.confidence_mean
                ep.jittering_score = result.jitter_score
                updated += 1
        
        session.commit()
        session.close()
        
        logger.info(f"DB ì—…ë°ì´íŠ¸: {updated}ê°œ ì—í”¼ì†Œë“œ")
        return updated
        
    except Exception as e:
        logger.error(f"DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return 0


def main():
    parser = argparse.ArgumentParser(description="P-ADE í’ˆì§ˆ í•„í„°ë§")
    
    parser.add_argument("--all", action="store_true", help="ëª¨ë“  í¬ì¦ˆ íŒŒì¼ ë¶„ì„")
    parser.add_argument("--file", help="ë‹¨ì¼ íŒŒì¼ ë¶„ì„")
    parser.add_argument("--analyze", action="store_true", help="ë¶„ì„ë§Œ ìˆ˜í–‰ (í•„í„°ë§ ì—†ìŒ)")
    parser.add_argument("--top-percent", type=float, default=None, help="ìƒìœ„ N%% ì„ íƒ")
    
    parser.add_argument("--poses-dir", default="data/poses", help="í¬ì¦ˆ ë””ë ‰í† ë¦¬")
    parser.add_argument("--output-dir", default="data/filtered", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--report", default=None, help="ë¦¬í¬íŠ¸ ì €ì¥ ê²½ë¡œ")
    
    # ì„ê³„ê°’ ì˜µì…˜
    parser.add_argument("--min-confidence", type=float, default=0.5, help="ìµœì†Œ ì‹ ë¢°ë„")
    parser.add_argument("--max-jitter", type=float, default=0.3, help="ìµœëŒ€ ì§€í„°")
    parser.add_argument("--min-frames", type=int, default=30, help="ìµœì†Œ í”„ë ˆì„ ìˆ˜")
    
    parser.add_argument("--update-db", action="store_true", help="DB ì—…ë°ì´íŠ¸")
    parser.add_argument("--dry-run", action="store_true", help="íŒŒì¼ ë³µì‚¬ ì—†ì´ ë¶„ì„ë§Œ")
    
    args = parser.parse_args()
    
    # ì„ê³„ê°’ ì„¤ì •
    thresholds = QualityThresholds(
        min_confidence=args.min_confidence,
        max_jitter_score=args.max_jitter,
        min_episode_frames=args.min_frames,
    )
    
    # í•„í„° ìƒì„±
    qf = QualityFilter(
        thresholds=thresholds,
        poses_dir=args.poses_dir,
        filtered_dir=args.output_dir,
    )
    
    results = []
    
    if args.file:
        # ë‹¨ì¼ íŒŒì¼ ë¶„ì„
        result = qf.analyze_file(Path(args.file))
        results = [result]
        
        print(f"\nğŸ“„ íŒŒì¼: {result.file_path}")
        print(f"   Video ID: {result.video_id}")
        print(f"   í†µê³¼: {'âœ… YES' if result.passed else 'âŒ NO'}")
        print(f"   í’ˆì§ˆ ì ìˆ˜: {result.quality_score:.3f}")
        print(f"   ì‹ ë¢°ë„: {result.confidence_mean:.3f}")
        print(f"   ì§€í„°: {result.jitter_score:.3f}")
        print(f"   NaN ë¹„ìœ¨: {result.nan_ratio:.3f}")
        print(f"   í”„ë ˆì„: {result.total_frames}")
        
        if result.failure_reasons:
            print(f"   ì‹¤íŒ¨ ì›ì¸:")
            for reason in result.failure_reasons:
                print(f"     - {reason}")
    
    elif args.all or args.analyze:
        # ëª¨ë“  íŒŒì¼ ë¶„ì„
        results = qf.analyze_all()
        
        if args.top_percent:
            # ìƒìœ„ N% ì„ íƒ
            top_results = qf.filter_top_percent(
                results,
                top_percent=args.top_percent,
                copy_files=not args.dry_run,
            )
            print(f"\nğŸ† ìƒìœ„ {args.top_percent}% ì„ íƒ: {len(top_results)}ê°œ")
            
            if not args.dry_run:
                print(f"   ì €ì¥ ê²½ë¡œ: {qf.filtered_dir}")
        
        elif not args.analyze:
            # ì„ê³„ê°’ ê¸°ë°˜ í•„í„°ë§
            passed, failed = qf.filter_by_threshold(
                results,
                copy_files=not args.dry_run,
            )
            
            if not args.dry_run and passed:
                print(f"\nğŸ“ í•„í„°ë§ëœ íŒŒì¼ ì €ì¥: {qf.filtered_dir}")
        
        # ìš”ì•½ ì¶œë ¥
        qf.print_summary(results)
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        if args.report:
            report = qf.generate_report(results, args.report)
            print(f"ğŸ“ ë¦¬í¬íŠ¸ ì €ì¥: {args.report}")
    
    else:
        parser.print_help()
        return
    
    # DB ì—…ë°ì´íŠ¸
    if args.update_db and results:
        updated = update_database_quality(results)
        print(f"ğŸ’¾ DB ì—…ë°ì´íŠ¸: {updated}ê°œ ì—í”¼ì†Œë“œ")


if __name__ == "__main__":
    main()
