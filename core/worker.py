"""
Worker Process - ë³‘ë ¬ ì‘ì—… ì²˜ë¦¬ ì›Œì»¤

MVP Phase 2 Week 5: Queue System
- ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ (4 workers)
- ì²˜ë¦¬ ì†ë„ 2ë°° ê°œì„ 
"""

import os
import sys
import time
import signal
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, Callable, List
from dataclasses import dataclass
from enum import Enum

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.logging_config import setup_logger
from core.queue_manager import (
    QueueManager,
    Task,
    TaskStatus,
    TaskPriority,
    InMemoryQueue,
)

logger = setup_logger(__name__)


class WorkerType(Enum):
    """ì›Œì»¤ íƒ€ì…"""
    DOWNLOAD = "download"
    EXTRACT = "extract"
    TRANSFORM = "transform"
    UPLOAD = "upload"


@dataclass
class WorkerConfig:
    """ì›Œì»¤ ì„¤ì •"""
    worker_type: WorkerType
    num_workers: int = 4
    poll_interval: float = 1.0  # ì´ˆ
    max_tasks_per_worker: int = 100
    timeout_per_task: int = 300  # 5ë¶„


class TaskProcessor:
    """
    ì‘ì—… ì²˜ë¦¬ê¸°
    
    ê° ì‘ì—… íƒ€ì…ë³„ ì‹¤ì œ ì²˜ë¦¬ ë¡œì§ì„ ë‹´ë‹¹
    """
    
    def __init__(self, base_dir: str = "data"):
        self.base_dir = Path(base_dir)
    
    def process_download(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¤ìš´ë¡œë“œ ì‘ì—… ì²˜ë¦¬"""
        video_id = payload.get("video_id")
        url = payload.get("url")
        
        logger.info(f"â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {video_id}")
        
        try:
            # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë¡œì§ (yt-dlp)
            import subprocess
            
            output_dir = self.base_dir / "raw"
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = output_dir / f"{video_id}.mp4"
            
            # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
            if output_path.exists():
                logger.info(f"â­ï¸ ì´ë¯¸ ì¡´ì¬: {output_path}")
                return {
                    "success": True,
                    "video_path": str(output_path),
                    "skipped": True,
                }
            
            # yt-dlpë¡œ ë‹¤ìš´ë¡œë“œ
            cmd = [
                "yt-dlp",
                "-f", "best[height<=720]",
                "-o", str(output_path),
                url,
            ]
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=payload.get("timeout", 300),
            )
            
            if result.returncode == 0 and output_path.exists():
                logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path}")
                return {
                    "success": True,
                    "video_path": str(output_path),
                    "size_bytes": output_path.stat().st_size,
                }
            else:
                raise Exception(f"yt-dlp ì‹¤íŒ¨: {result.stderr}")
                
        except subprocess.TimeoutExpired:
            raise Exception("ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ")
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def process_extract(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """í¬ì¦ˆ ì¶”ì¶œ ì‘ì—… ì²˜ë¦¬"""
        video_id = payload.get("video_id")
        video_path = payload.get("video_path")
        
        logger.info(f"ğŸ¦´ í¬ì¦ˆ ì¶”ì¶œ ì‹œì‘: {video_id}")
        
        try:
            import cv2
            import numpy as np
            import mediapipe as mp
            
            output_dir = self.base_dir / "poses"
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = output_dir / f"{video_id}_pose.npz"
            
            # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìŠ¤í‚µ
            if output_path.exists():
                logger.info(f"â­ï¸ ì´ë¯¸ ì¡´ì¬: {output_path}")
                return {
                    "success": True,
                    "pose_path": str(output_path),
                    "skipped": True,
                }
            
            # MediaPipe Pose ì´ˆê¸°í™”
            mp_pose = mp.solutions.pose
            pose = mp_pose.Pose(
                static_image_mode=False,
                model_complexity=1,
                min_detection_confidence=0.5,
                min_tracking_confidence=0.5,
            )
            
            # ë¹„ë””ì˜¤ ì½ê¸°
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise Exception(f"ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            poses = []
            confidences = []
            frame_indices = []
            
            frame_idx = 0
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                # BGR -> RGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                results = pose.process(rgb_frame)
                
                if results.pose_landmarks:
                    # ëœë“œë§ˆí¬ ì¶”ì¶œ
                    landmarks = []
                    for lm in results.pose_landmarks.landmark:
                        landmarks.extend([lm.x, lm.y, lm.z, lm.visibility])
                    
                    poses.append(landmarks)
                    confidences.append(
                        np.mean([lm.visibility for lm in results.pose_landmarks.landmark])
                    )
                    frame_indices.append(frame_idx)
                
                frame_idx += 1
            
            cap.release()
            pose.close()
            
            if not poses:
                raise Exception("í¬ì¦ˆ ê°ì§€ ì‹¤íŒ¨")
            
            # ì €ì¥
            np.savez_compressed(
                output_path,
                poses=np.array(poses, dtype=np.float32),
                confidences=np.array(confidences, dtype=np.float32),
                frame_indices=np.array(frame_indices, dtype=np.int32),
                fps=fps,
                total_frames=total_frames,
                video_id=video_id,
            )
            
            logger.info(f"âœ… í¬ì¦ˆ ì¶”ì¶œ ì™„ë£Œ: {len(poses)} í”„ë ˆì„")
            
            return {
                "success": True,
                "pose_path": str(output_path),
                "num_frames": len(poses),
                "avg_confidence": float(np.mean(confidences)),
            }
            
        except Exception as e:
            logger.error(f"âŒ í¬ì¦ˆ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def process_transform(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """ë³€í™˜ ì‘ì—… ì²˜ë¦¬"""
        video_id = payload.get("video_id")
        pose_path = payload.get("pose_path")
        
        logger.info(f"ğŸ”„ ë³€í™˜ ì‹œì‘: {video_id}")
        
        try:
            import numpy as np
            
            output_dir = self.base_dir / "episodes"
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # í¬ì¦ˆ ë°ì´í„° ë¡œë“œ
            data = np.load(pose_path)
            poses = data["poses"]
            confidences = data["confidences"]
            fps = float(data["fps"])
            
            # ì—í”¼ì†Œë“œ ë¶„í•  (ê°„ë‹¨í•œ êµ¬í˜„)
            # ì‹¤ì œë¡œëŠ” segment_episodes.pyì˜ ë¡œì§ ì‚¬ìš©
            min_episode_frames = int(fps * 2)  # ìµœì†Œ 2ì´ˆ
            
            episodes = []
            current_start = 0
            
            for i, conf in enumerate(confidences):
                if conf < 0.3 and i - current_start >= min_episode_frames:
                    episodes.append({
                        "start_frame": current_start,
                        "end_frame": i,
                        "avg_confidence": float(np.mean(confidences[current_start:i])),
                    })
                    current_start = i + 1
            
            # ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œ
            if len(poses) - current_start >= min_episode_frames:
                episodes.append({
                    "start_frame": current_start,
                    "end_frame": len(poses),
                    "avg_confidence": float(np.mean(confidences[current_start:])),
                })
            
            logger.info(f"âœ… ë³€í™˜ ì™„ë£Œ: {len(episodes)} ì—í”¼ì†Œë“œ")
            
            return {
                "success": True,
                "num_episodes": len(episodes),
                "episodes": episodes,
            }
            
        except Exception as e:
            logger.error(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}")
            raise
    
    def process_upload(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """ì—…ë¡œë“œ ì‘ì—… ì²˜ë¦¬"""
        video_id = payload.get("video_id")
        file_path = payload.get("file_path")
        
        logger.info(f"â˜ï¸ ì—…ë¡œë“œ ì‹œì‘: {video_id}")
        
        try:
            from storage.providers.s3_provider import S3Provider
            from config.settings import Config
            
            config = Config()
            s3 = S3Provider(
                bucket_name=config.get("AWS_S3_BUCKET", "p-ade-datasets"),
                region=config.get("AWS_REGION", "us-east-1"),
            )
            
            # S3 í‚¤ ìƒì„±
            now = datetime.now()
            filename = Path(file_path).name
            s3_key = f"poses/{now.year}/{now.month:02d}/{now.day:02d}/{filename}"
            
            # ì—…ë¡œë“œ
            s3.upload_file(file_path, s3_key)
            
            s3_uri = f"s3://{s3.bucket_name}/{s3_key}"
            logger.info(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ: {s3_uri}")
            
            return {
                "success": True,
                "s3_uri": s3_uri,
                "s3_key": s3_key,
            }
            
        except Exception as e:
            logger.error(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def process(self, task: Task) -> Dict[str, Any]:
        """ì‘ì—… íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬"""
        handlers = {
            "download": self.process_download,
            "extract": self.process_extract,
            "transform": self.process_transform,
            "upload": self.process_upload,
        }
        
        handler = handlers.get(task.task_type)
        if not handler:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—… íƒ€ì…: {task.task_type}")
        
        return handler(task.payload)


class Worker:
    """
    ì›Œì»¤ í”„ë¡œì„¸ìŠ¤
    
    íì—ì„œ ì‘ì—…ì„ ê°€ì ¸ì™€ ì²˜ë¦¬
    """
    
    def __init__(
        self,
        worker_id: str,
        queue_manager: QueueManager,
        queue_name: str,
        processor: TaskProcessor,
    ):
        self.worker_id = worker_id
        self.qm = queue_manager
        self.queue_name = queue_name
        self.processor = processor
        self._running = False
    
    def start(self):
        """ì›Œì»¤ ì‹œì‘"""
        self._running = True
        logger.info(f"ğŸŸ¢ Worker {self.worker_id} ì‹œì‘ (queue={self.queue_name})")
        
        while self._running:
            try:
                # ì‘ì—… ê°€ì ¸ì˜¤ê¸°
                task = self.qm.get_next_task(self.queue_name, timeout=1)
                
                if task:
                    task.worker_id = self.worker_id
                    logger.info(f"ğŸ“¥ Worker {self.worker_id}: ì‘ì—… ìˆ˜ì‹  - {task.task_id}")
                    
                    try:
                        # ì‘ì—… ì²˜ë¦¬
                        result = self.processor.process(task)
                        self.qm.complete_task(self.queue_name, task, result)
                        logger.info(f"âœ… Worker {self.worker_id}: ì‘ì—… ì™„ë£Œ - {task.task_id}")
                        
                    except Exception as e:
                        error_msg = str(e)
                        self.qm.fail_task(self.queue_name, task, error_msg, retry=True)
                        logger.error(f"âŒ Worker {self.worker_id}: ì‘ì—… ì‹¤íŒ¨ - {error_msg}")
                
            except Exception as e:
                logger.error(f"Worker {self.worker_id} ì˜¤ë¥˜: {e}")
                time.sleep(1)
        
        logger.info(f"ğŸ”´ Worker {self.worker_id} ì¢…ë£Œ")
    
    def stop(self):
        """ì›Œì»¤ ì¤‘ì§€"""
        self._running = False


class WorkerPool:
    """
    ì›Œì»¤ í’€
    
    ì—¬ëŸ¬ ì›Œì»¤ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
    """
    
    def __init__(
        self,
        queue_manager: QueueManager,
        num_workers: int = 4,
        base_dir: str = "data",
    ):
        self.qm = queue_manager
        self.num_workers = num_workers
        self.processor = TaskProcessor(base_dir)
        self.workers: List[Worker] = []
        self._executor: Optional[ThreadPoolExecutor] = None
        self._running = False
    
    def start(self, queue_name: str):
        """ì›Œì»¤ í’€ ì‹œì‘"""
        self._running = True
        self._executor = ThreadPoolExecutor(max_workers=self.num_workers)
        
        logger.info(f"ğŸš€ WorkerPool ì‹œì‘: {self.num_workers} workers (queue={queue_name})")
        
        futures = []
        for i in range(self.num_workers):
            worker = Worker(
                worker_id=f"worker-{i+1}",
                queue_manager=self.qm,
                queue_name=queue_name,
                processor=self.processor,
            )
            self.workers.append(worker)
            futures.append(self._executor.submit(worker.start))
        
        return futures
    
    def stop(self):
        """ì›Œì»¤ í’€ ì¤‘ì§€"""
        logger.info("ğŸ›‘ WorkerPool ì¤‘ì§€ ì¤‘...")
        self._running = False
        
        for worker in self.workers:
            worker.stop()
        
        if self._executor:
            self._executor.shutdown(wait=True)
        
        self.workers.clear()
        logger.info("âœ… WorkerPool ì¤‘ì§€ ì™„ë£Œ")
    
    def get_stats(self) -> Dict[str, Any]:
        """í’€ í†µê³„"""
        return {
            "num_workers": self.num_workers,
            "active_workers": len([w for w in self.workers if w._running]),
            "queue_stats": self.qm.get_queue_stats(),
        }


def process_batch_parallel(
    items: List[Dict[str, Any]],
    task_type: str,
    num_workers: int = 4,
    use_redis: bool = False,
) -> List[Dict[str, Any]]:
    """
    ë°°ì¹˜ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    
    Args:
        items: ì²˜ë¦¬í•  í•­ëª© ëª©ë¡
        task_type: ì‘ì—… íƒ€ì… (download, extract, transform, upload)
        num_workers: ì›Œì»¤ ìˆ˜
        use_redis: Redis ì‚¬ìš© ì—¬ë¶€
    
    Returns:
        ê²°ê³¼ ëª©ë¡
    """
    qm = QueueManager(use_redis=use_redis)
    processor = TaskProcessor()
    
    # ì‘ì—… ì œì¶œ
    logger.info(f"ğŸ“¤ {len(items)}ê°œ ì‘ì—… ì œì¶œ ì¤‘...")
    
    task_ids = []
    for item in items:
        task = qm.create_task(task_type, item)
        qm.backend.enqueue(task_type, task)
        task_ids.append(task.task_id)
    
    # ë³‘ë ¬ ì²˜ë¦¬
    results = []
    
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        def process_one():
            task = qm.get_next_task(task_type)
            if task:
                try:
                    result = processor.process(task)
                    qm.complete_task(task_type, task, result)
                    return {"task_id": task.task_id, "success": True, **result}
                except Exception as e:
                    qm.fail_task(task_type, task, str(e), retry=False)
                    return {"task_id": task.task_id, "success": False, "error": str(e)}
            return None
        
        futures = [executor.submit(process_one) for _ in items]
        
        for future in as_completed(futures):
            result = future.result()
            if result:
                results.append(result)
    
    success_count = len([r for r in results if r.get("success")])
    logger.info(f"âœ… ì™„ë£Œ: {success_count}/{len(items)} ì„±ê³µ")
    
    return results


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="P-ADE Worker")
    parser.add_argument("--queue", default="download", choices=["download", "extract", "transform", "upload"])
    parser.add_argument("--workers", type=int, default=4)
    parser.add_argument("--redis", action="store_true", help="Redis ì‚¬ìš©")
    args = parser.parse_args()
    
    print(f"=== P-ADE Worker Pool ===")
    print(f"Queue: {args.queue}")
    print(f"Workers: {args.workers}")
    print(f"Redis: {args.redis}")
    print()
    
    # í ë§¤ë‹ˆì € ìƒì„±
    qm = QueueManager(use_redis=args.redis)
    
    # ì›Œì»¤ í’€ ì‹œì‘
    pool = WorkerPool(qm, num_workers=args.workers)
    
    # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬
    def signal_handler(sig, frame):
        print("\nâš ï¸ ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ...")
        pool.stop()
        sys.exit(0)
    
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    try:
        futures = pool.start(args.queue)
        
        # ì™„ë£Œ ëŒ€ê¸°
        for future in as_completed(futures):
            pass
            
    except KeyboardInterrupt:
        pool.stop()
