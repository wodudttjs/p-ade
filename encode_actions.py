#!/usr/bin/env python
"""
Action Encoding CLI

MVP Phase 2 Week 7: Action Encoding
- State-Action ìŒ ìƒì„±
- Delta position ê³„ì‚°
- í‘œì¤€í™”ëœ ë°ì´í„° í¬ë§·

ì‚¬ìš©ë²•:
    python encode_actions.py --all                    # ëª¨ë“  í¬ì¦ˆ ë³€í™˜
    python encode_actions.py --file pose.npz          # ë‹¨ì¼ íŒŒì¼ ë³€í™˜
    python encode_actions.py --all --output episodes  # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì§€ì •
"""

import os
import sys
import argparse
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import shutil

import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from core.logging_config import setup_logger
from transformation.encoding import StateBuilder, ActionComputer, StateActionPair
from transformation.spec import TransformConfig, StateSpec, ActionSpec

logger = setup_logger(__name__)


@dataclass
class EncodingResult:
    """ì¸ì½”ë”© ê²°ê³¼"""
    file_path: str
    video_id: str
    success: bool
    output_path: Optional[str] = None
    num_frames: int = 0
    state_dim: int = 0
    action_dim: int = 0
    error: Optional[str] = None


class ActionEncoder:
    """Action Encoding í´ë˜ìŠ¤"""
    
    def __init__(
        self,
        poses_dir: str = "data/poses",
        output_dir: str = "data/episodes",
        config: Optional[TransformConfig] = None,
    ):
        self.poses_dir = Path(poses_dir)
        self.output_dir = Path(output_dir)
        self.config = config or TransformConfig()
        
        # State/Action builders
        self.state_builder = StateBuilder(
            config=self.config,
            state_spec=StateSpec(
                joint_positions=True,
                joint_velocities=True,
                object_relations=False,
                confidence_stats=True,
            ),
        )
        
        self.action_computer = ActionComputer(
            config=self.config,
            action_spec=ActionSpec(
                position_delta=True,
                rotation_delta=False,
                gripper_state=False,
                eef_only=True,
            ),
        )
    
    def load_pose_data(self, file_path: Path) -> Dict[str, np.ndarray]:
        """í¬ì¦ˆ ë°ì´í„° ë¡œë“œ"""
        data = np.load(file_path, allow_pickle=True)
        
        result = {}
        
        # Body poses
        for key in ["poses", "body", "keypoints"]:
            if key in data:
                result["poses"] = data[key]
                break
        
        # Hand landmarks
        if "left_hand" in data and "right_hand" in data:
            left = data["left_hand"]
            right = data["right_hand"]
            if len(left.shape) == 3 and len(right.shape) == 3:
                result["hands"] = np.stack([left, right], axis=1)
        
        # Confidence
        for key in ["confidences", "confidence", "conf"]:
            if key in data:
                result["confidence"] = data[key]
                break
        
        # Timestamps
        if "timestamps" in data:
            result["timestamps"] = data["timestamps"]
        
        # FPS
        if "fps" in data:
            result["fps"] = float(data["fps"])
        elif "metadata" in data:
            meta = data["metadata"]
            if hasattr(meta, "__len__") and len(meta) >= 1:
                result["fps"] = float(meta[0]) if meta[0] > 0 else 30.0
            else:
                result["fps"] = 30.0
        else:
            result["fps"] = 30.0
        
        return result
    
    def compute_velocity(self, poses: np.ndarray, fps: float = 30.0) -> np.ndarray:
        """ì†ë„ ê³„ì‚°"""
        dt = 1.0 / fps
        
        # ì¤‘ì•™ ì°¨ë¶„ (central difference)
        velocity = np.zeros_like(poses)
        velocity[1:-1] = (poses[2:] - poses[:-2]) / (2 * dt)
        velocity[0] = (poses[1] - poses[0]) / dt
        velocity[-1] = (poses[-1] - poses[-2]) / dt
        
        return velocity
    
    def normalize_poses(self, poses: np.ndarray) -> np.ndarray:
        """í¬ì¦ˆ ì •ê·œí™” (hip ì¤‘ì‹¬, scale ì •ê·œí™”)"""
        # Hip center (MediaPipe: 23=left_hip, 24=right_hip)
        if poses.shape[1] >= 25:
            hip_center = (poses[:, 23, :] + poses[:, 24, :]) / 2
        else:
            hip_center = np.mean(poses, axis=1)
        
        # ì¤‘ì‹¬ ì´ë™
        normalized = poses - hip_center[:, np.newaxis, :]
        
        # Scale ì •ê·œí™” (ì–´ê¹¨ ë„ˆë¹„ ê¸°ì¤€)
        if poses.shape[1] >= 12:
            shoulder_width = np.linalg.norm(
                poses[:, 11, :] - poses[:, 12, :], axis=1
            )
            scale = np.clip(shoulder_width, 0.1, 2.0)
            normalized = normalized / scale[:, np.newaxis, np.newaxis]
        
        return normalized
    
    def encode_file(self, file_path: Path) -> EncodingResult:
        """ë‹¨ì¼ íŒŒì¼ ì¸ì½”ë”©"""
        video_id = file_path.stem.replace("_pose", "")
        
        try:
            # ë°ì´í„° ë¡œë“œ
            data = self.load_pose_data(file_path)
            
            if "poses" not in data:
                raise ValueError("í¬ì¦ˆ ë°ì´í„° ì—†ìŒ")
            
            poses = data["poses"]
            fps = data.get("fps", 30.0)
            confidence = data.get("confidence", None)
            hands = data.get("hands", None)
            timestamps = data.get("timestamps", None)
            
            T = poses.shape[0]
            
            if T < 2:
                raise ValueError(f"í”„ë ˆì„ ìˆ˜ ë¶€ì¡±: {T}")
            
            # í¬ì¦ˆ ì •ê·œí™”
            normalized_poses = self.normalize_poses(poses)
            
            # ì†ë„ ê³„ì‚°
            velocity = self.compute_velocity(normalized_poses, fps)
            
            # State ìƒì„±
            states, state_masks = self.state_builder.build_state(
                pose=normalized_poses,
                velocity=velocity,
                conf=confidence,
            )
            
            # Action ê³„ì‚°
            actions, action_masks = self.action_computer.compute_action(
                pose=normalized_poses,
                dt=1.0 / fps,
            )
            
            # Gripper state ì¶”ì • (ì† ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            gripper_states = None
            if hands is not None:
                gripper_states = self.action_computer.estimate_gripper_state(hands)
            
            # Timestamps ìƒì„±
            if timestamps is None:
                timestamps = np.arange(T) / fps
            
            # ì¶œë ¥ ì €ì¥
            self.output_dir.mkdir(parents=True, exist_ok=True)
            output_path = self.output_dir / f"{video_id}_episode.npz"
            
            save_dict = {
                # State-Action pairs
                "states": states.astype(np.float32),
                "actions": actions.astype(np.float32),
                "state_masks": state_masks,
                "action_masks": action_masks,
                
                # Raw data
                "poses": normalized_poses.astype(np.float32),
                "velocity": velocity.astype(np.float32),
                "timestamps": timestamps.astype(np.float32),
                
                # Metadata
                "fps": fps,
                "video_id": video_id,
                "state_dim": states.shape[1],
                "action_dim": actions.shape[1],
                "num_frames": T,
            }
            
            if confidence is not None:
                save_dict["confidence"] = confidence.astype(np.float32)
            
            if gripper_states is not None:
                save_dict["gripper_states"] = gripper_states.astype(np.float32)
            
            np.savez_compressed(output_path, **save_dict)
            
            return EncodingResult(
                file_path=str(file_path),
                video_id=video_id,
                success=True,
                output_path=str(output_path),
                num_frames=T,
                state_dim=states.shape[1],
                action_dim=actions.shape[1],
            )
            
        except Exception as e:
            logger.error(f"ì¸ì½”ë”© ì‹¤íŒ¨ {file_path}: {e}")
            return EncodingResult(
                file_path=str(file_path),
                video_id=video_id,
                success=False,
                error=str(e),
            )
    
    def encode_all(self) -> List[EncodingResult]:
        """ëª¨ë“  í¬ì¦ˆ íŒŒì¼ ì¸ì½”ë”©"""
        results = []
        
        pose_files = list(self.poses_dir.glob("*_pose.npz"))
        
        if not pose_files:
            logger.warning(f"í¬ì¦ˆ íŒŒì¼ ì—†ìŒ: {self.poses_dir}")
            return results
        
        print(f"\n{'='*60}")
        print(f"ğŸ¬ Action Encoding ì‹œì‘")
        print(f"{'='*60}")
        print(f"ğŸ“ ì…ë ¥: {self.poses_dir}")
        print(f"ğŸ“ ì¶œë ¥: {self.output_dir}")
        print(f"ğŸ“¦ íŒŒì¼: {len(pose_files)}ê°œ")
        print()
        
        for i, file_path in enumerate(pose_files, 1):
            result = self.encode_file(file_path)
            results.append(result)
            
            if result.success:
                status = f"âœ… ({result.num_frames} frames, S:{result.state_dim}, A:{result.action_dim})"
            else:
                status = f"âŒ {result.error}"
            
            print(f"[{i}/{len(pose_files)}] {result.video_id}: {status}")
        
        return results
    
    def print_summary(self, results: List[EncodingResult]):
        """ìš”ì•½ ì¶œë ¥"""
        if not results:
            print("ê²°ê³¼ ì—†ìŒ")
            return
        
        success = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        print()
        print("="*60)
        print("ğŸ“Š ì¸ì½”ë”© ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        print(f"\nğŸ“ˆ ìš”ì•½:")
        print(f"   ì´ íŒŒì¼: {len(results)}ê°œ")
        print(f"   âœ… ì„±ê³µ: {len(success)}ê°œ ({len(success)/len(results)*100:.1f}%)")
        print(f"   âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
        
        if success:
            total_frames = sum(r.num_frames for r in success)
            avg_state_dim = sum(r.state_dim for r in success) / len(success)
            avg_action_dim = sum(r.action_dim for r in success) / len(success)
            
            print(f"\nğŸ“Š í†µê³„:")
            print(f"   ì´ í”„ë ˆì„: {total_frames}")
            print(f"   í‰ê·  State ì°¨ì›: {avg_state_dim:.0f}")
            print(f"   í‰ê·  Action ì°¨ì›: {avg_action_dim:.0f}")
        
        if failed:
            print(f"\nâŒ ì‹¤íŒ¨ ëª©ë¡:")
            for r in failed:
                print(f"   - {r.video_id}: {r.error}")
        
        print()


def inspect_episode(file_path: str):
    """ì—í”¼ì†Œë“œ íŒŒì¼ ìƒì„¸ ê²€ì‚¬"""
    data = np.load(file_path)
    
    print(f"\nğŸ“„ íŒŒì¼: {file_path}")
    print(f"{'='*60}")
    
    print("\nğŸ“¦ ë°ì´í„° í‚¤:")
    for key in data.keys():
        arr = data[key]
        if hasattr(arr, 'shape'):
            print(f"   {key}: shape={arr.shape}, dtype={arr.dtype}")
        else:
            print(f"   {key}: {arr}")
    
    if "states" in data:
        states = data["states"]
        print(f"\nğŸ¯ States:")
        print(f"   Shape: {states.shape}")
        print(f"   Mean: {np.mean(states):.4f}")
        print(f"   Std: {np.std(states):.4f}")
        print(f"   Min: {np.min(states):.4f}")
        print(f"   Max: {np.max(states):.4f}")
    
    if "actions" in data:
        actions = data["actions"]
        print(f"\nğŸš€ Actions:")
        print(f"   Shape: {actions.shape}")
        print(f"   Mean: {np.mean(actions):.6f}")
        print(f"   Std: {np.std(actions):.6f}")
        print(f"   Min: {np.min(actions):.6f}")
        print(f"   Max: {np.max(actions):.6f}")
    
    print()


def main():
    parser = argparse.ArgumentParser(description="P-ADE Action Encoding")
    
    parser.add_argument("--all", action="store_true", help="ëª¨ë“  í¬ì¦ˆ íŒŒì¼ ì¸ì½”ë”©")
    parser.add_argument("--file", help="ë‹¨ì¼ íŒŒì¼ ì¸ì½”ë”©")
    parser.add_argument("--inspect", help="ì—í”¼ì†Œë“œ íŒŒì¼ ê²€ì‚¬")
    
    parser.add_argument("--poses-dir", default="data/poses", help="í¬ì¦ˆ ë””ë ‰í† ë¦¬")
    parser.add_argument("--output-dir", default="data/episodes", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    
    parser.add_argument("--eef-only", action="store_true", default=True,
                        help="End-effectorë§Œ ì‚¬ìš© (ê¸°ë³¸ê°’)")
    parser.add_argument("--all-joints", action="store_true",
                        help="ì „ì²´ ê´€ì ˆ ì‚¬ìš©")
    
    args = parser.parse_args()
    
    if args.inspect:
        inspect_episode(args.inspect)
        return
    
    # ì¸ì½”ë” ìƒì„±
    encoder = ActionEncoder(
        poses_dir=args.poses_dir,
        output_dir=args.output_dir,
    )
    
    if args.all_joints:
        encoder.action_computer.action_spec.eef_only = False
    
    results = []
    
    if args.file:
        result = encoder.encode_file(Path(args.file))
        results = [result]
        
        if result.success:
            print(f"\nâœ… ì¸ì½”ë”© ì™„ë£Œ: {result.output_path}")
            print(f"   í”„ë ˆì„: {result.num_frames}")
            print(f"   State ì°¨ì›: {result.state_dim}")
            print(f"   Action ì°¨ì›: {result.action_dim}")
        else:
            print(f"\nâŒ ì¸ì½”ë”© ì‹¤íŒ¨: {result.error}")
    
    elif args.all:
        results = encoder.encode_all()
        encoder.print_summary(results)
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
